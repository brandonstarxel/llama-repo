{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/paperspace/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:15<00:00,  3.90s/it]\n",
      "LlamaModel is using LlamaSdpaAttention, but `torch.nn.functional.scaled_dot_product_attention` does not support `output_attentions=True`. Falling back to the manual attention implementation, but specifying the manual implementation will be required from Transformers version v5.0.0 onwards. This warning can be removed using the argument `attn_implementation=\"eager\"` when loading the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "155 37 823\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import matplotlib.pyplot as plt\n",
    "# from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "import numpy as np\n",
    "\n",
    "# Load the tokenizer and model\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Meta-Llama-3-8B-Instruct\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"meta-llama/Meta-Llama-3-8B-Instruct\")\n",
    "\n",
    "# import tiktoken\n",
    "\n",
    "# # Count the number of tokens in each page_content\n",
    "# def num_tokens_from_string(string: str) -> int:\n",
    "#     \"\"\"Returns the number of tokens in a text string.\"\"\"\n",
    "#     encoding = tiktoken.get_encoding(\"cl100k_base\")\n",
    "#     num_tokens = len(encoding.encode(string, disallowed_special=()))\n",
    "#     return num_tokens\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "with open('/home/paperspace/llama-repo/corpuses/wikitexts.md', 'r') as file:\n",
    "    input_text = file.read()\n",
    "\n",
    "# chunks = splitter.split_text(input_text)\n",
    "\n",
    "# Define the input text\n",
    "# input_texts = [input_text[i:i+6000] for i in range(0, len(input_text), 6000)]\n",
    "\n",
    "i = 2\n",
    "input_text = input_text[i*4000:(i+1)*4000]\n",
    "\n",
    "prompt_first_half = \"\"\"\n",
    "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
    "\n",
    "You are an assistant specialized in splitting a corpus into thematically consistent sections. Read the following corpus and identify the points where splits should occur, such to create consecutive strips of similar themes. Respond with the text of each chunk. Here is an example response:\n",
    "\n",
    "CORPUS: \"The Ferari is a fast car. The Lamborghini is also a fast car. Toast can be made with bread. The toaster is used to make toast.\"\n",
    "\n",
    "RESPONSE:\n",
    "First Chunk: \"The Ferari is a fast car. The Lamborghini is also a fast car.\"\n",
    "Second Chunk: \"Toast can be made with bread. The toaster is used to make toast.\"\n",
    "\n",
    "Here is the corpus you will be working with:\n",
    "\n",
    "<|begin_of_corpus|>\"\"\"\n",
    "\n",
    "token_count = 0\n",
    "defined_chunks = []\n",
    "\n",
    "# input_text = input_texts[0]\n",
    "\n",
    "# for input_text in input_texts:\n",
    "promt_second_half = \"\"\"<|end_of_corpus|>\n",
    "\n",
    "Respond with the chunk and it's corresponding text from the corpus above:<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
    "\n",
    "First Chunk: TEXT\n",
    "Second Chunk: TEXT\n",
    "\"\"\"\n",
    "\n",
    "len_of_first_half = len(tokenizer.encode(prompt_first_half, return_tensors='pt')[0])\n",
    "len_of_second_half = len(tokenizer.encode(promt_second_half, return_tensors='pt')[0])\n",
    "len_of_corpus = len(tokenizer.encode(input_text, return_tensors='pt')[0])\n",
    "\n",
    "print(len_of_first_half, len_of_second_half, len_of_corpus)\n",
    "\n",
    "prompt = prompt_first_half + input_text + promt_second_half\n",
    "\n",
    "# Tokenize the input text\n",
    "input_ids = tokenizer.encode(prompt, return_tensors='pt')\n",
    "\n",
    "print(len(input_ids))\n",
    "\n",
    "# Get the model's outputs without tracking gradients\n",
    "with torch.no_grad():\n",
    "    outputs = model(input_ids, output_attentions=True)\n",
    "\n",
    "# Unload the model from memory\n",
    "torch.cuda.empty_cache()\n",
    "del model\n",
    "torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[(0, 300), (523, 823)]]\n"
     ]
    }
   ],
   "source": [
    "prompt_len = len(input_ids[-1])\n",
    "\n",
    "# third_chunk_index = (prompt_len-5, prompt_len-1)\n",
    "# second_chunk_index = (prompt_len-10, prompt_len-6)\n",
    "# first_chunk_index = (prompt_len-15, prompt_len-11)\n",
    "\n",
    "second_chunk_index = (prompt_len-5, prompt_len-1)\n",
    "first_chunk_index = (prompt_len-10, prompt_len-6)\n",
    "\n",
    "start_corpus_index = len_of_first_half\n",
    "end_of_corpus_index = len_of_first_half + len_of_corpus\n",
    "\n",
    "window_size = 300\n",
    "\n",
    "chunks = []\n",
    "\n",
    "attention_matrix_original = torch.max(torch.stack(outputs.attentions), dim=0).values.detach().numpy()\n",
    "\n",
    "prompt_len = len(input_ids[-1])\n",
    "\n",
    "third_chunk_index = (prompt_len-5, prompt_len-1)\n",
    "second_chunk_index = (prompt_len-10, prompt_len-6)\n",
    "first_chunk_index = (prompt_len-15, prompt_len-11)\n",
    "\n",
    "start_corpus_index = len_of_first_half\n",
    "end_of_corpus_index = len_of_first_half + len_of_corpus\n",
    "\n",
    "window_size = 300\n",
    "\n",
    "chunks = []\n",
    "\n",
    "attention_matrix_original = torch.max(torch.stack(outputs.attentions), dim=0).values.detach().numpy()\n",
    "\n",
    "# for chunk_index in [first_chunk_index, second_chunk_index, third_chunk_index]:\n",
    "for chunk_index in [first_chunk_index, second_chunk_index]:\n",
    "    attention_matrix = attention_matrix_original.copy()\n",
    "\n",
    "    attention_matrix = attention_matrix[:, -20:, :, :]\n",
    "    attention_matrix = np.max(attention_matrix, axis=1)\n",
    "\n",
    "    attention_matrix = attention_matrix[0, chunk_index[0]:chunk_index[1], :]\n",
    "    attention_matrix = np.sum(attention_matrix, axis=0)\n",
    "\n",
    "    # No overlap with previous chunks\n",
    "    for prev_chunk in chunks:\n",
    "        attention_matrix[prev_chunk[0]:prev_chunk[1]] = -np.inf\n",
    "\n",
    "    # Initialize the best sum and best position\n",
    "    best_sum = -np.inf\n",
    "    best_position = -1\n",
    "\n",
    "    # Iterate over the possible start positions of the window\n",
    "    for start_position in range(start_corpus_index, end_of_corpus_index - window_size + 1):\n",
    "        # Calculate the sum of the window\n",
    "        window_sum = np.sum(attention_matrix[start_position:start_position + window_size])\n",
    "        \n",
    "        # If this sum is better than the current best, update the best sum and best position\n",
    "        if window_sum > best_sum:\n",
    "            best_sum = window_sum\n",
    "            best_position = start_position\n",
    "\n",
    "    chunks.append((best_position, best_position + window_size))\n",
    "\n",
    "defined_chunks.append([(chunk[0]-len_of_first_half+token_count, chunk[1]-len_of_first_half+token_count) for chunk in chunks])\n",
    "print(defined_chunks)\n",
    "\n",
    "token_count += len_of_corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[[(0, 300), (518, 818)]]\n",
    "+818\n",
    "[[(0, 300), (536, 836)]]\n",
    "+836\n",
    "[[(0, 300), (523, 823)]]\n",
    "+823\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last 5 tokens:  First Chunk: TEXT\n"
     ]
    }
   ],
   "source": [
    "prompt_len = len(input_ids[-1])\n",
    "\n",
    "third_chunk_index = (prompt_len-5, prompt_len-1)\n",
    "second_chunk_index = (prompt_len-10, prompt_len-6)\n",
    "first_chunk_index = (prompt_len-15, prompt_len-11)\n",
    "\n",
    "# Get the last 5 input_ids\n",
    "last_5_input_ids = input_ids[0][first_chunk_index[0]:first_chunk_index[1]]\n",
    "\n",
    "# Decode the last 5 input_ids\n",
    "last_5_tokens = tokenizer.decode(last_5_input_ids)\n",
    "\n",
    "# Print the last 5 tokens\n",
    "print(\"Last 5 tokens: \", last_5_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "start_corpus_index = len_of_first_half\n",
    "end_of_corpus_index = len_of_first_half + len_of_corpus\n",
    "\n",
    "window_size = 300\n",
    "\n",
    "chunks = []\n",
    "\n",
    "for chunk_index in [first_chunk_index, second_chunk_index, third_chunk_index]:\n",
    "    attention_matrix = torch.max(torch.stack(outputs.attentions), dim=0).values.detach().numpy()\n",
    "\n",
    "    attention_matrix = attention_matrix[:, -20:, :, :]\n",
    "    attention_matrix = np.max(attention_matrix, axis=1)\n",
    "\n",
    "    attention_matrix = attention_matrix[0, chunk_index[0]:chunk_index[1], :]\n",
    "    attention_matrix = np.sum(attention_matrix, axis=0)\n",
    "\n",
    "    # No overlap with previous chunks\n",
    "    for prev_chunk in chunks:\n",
    "        attention_matrix[prev_chunk[0]:prev_chunk[1]] = -np.inf\n",
    "\n",
    "    # Initialize the best sum and best position\n",
    "    best_sum = -np.inf\n",
    "    best_position = -1\n",
    "\n",
    "    # Iterate over the possible start positions of the window\n",
    "    for start_position in range(start_corpus_index, end_of_corpus_index - window_size + 1):\n",
    "        # Calculate the sum of the window\n",
    "        window_sum = np.sum(attention_matrix[start_position:start_position + window_size])\n",
    "        \n",
    "        # If this sum is better than the current best, update the best sum and best position\n",
    "        if window_sum > best_sum:\n",
    "            best_sum = window_sum\n",
    "            best_position = start_position\n",
    "\n",
    "    chunks.append((best_position, best_position + window_size))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(155, 455), (1087, 1387), (486, 786)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " = Valkyria Chronicles III = \n",
      " Senjō no Valkyria 3 : <unk> Chronicles ( Japanese : 戦場のヴァルキュリア3, lit. Valkyria of the Battlefield 3 ), commonly referred to as Valkyria Chronicles III outside Japan, is a tactical role @-@ playing video game developed by Sega and Media.Vision for the PlayStation Portable. Released in January 2011 in Japan, it is the third game in the Valkyria series. Employing the same fusion of tactical and real @-@ time gameplay as its predecessors, the story runs parallel to the first game and follows the \" Nameless \", a penal military unit serving the nation of Gallia during the Second Europan War who perform secret black operations and are pitted against the Imperial unit \" <unk> Raven \". \n",
      " The game began development in 2010, carrying over a large portion of the work done on Valkyria Chronicles II. While it retained the standard features of the series, it also underwent multiple adjustments, such as making the game more forgiving for series newcomers. Character designer <unk> Honjou and composer Hitoshi Sakimoto both returned from previous entries, along with Valkyria Chronicles II director Takeshi Ozawa. A large team of writers handled the script. The game's opening theme was sung by May 'n. \n",
      " It met with positive sales in Japan, and was praised by both Japanese and western critics. After\n",
      "-1\n",
      "\n",
      "\n",
      "\n",
      " Valkyria Form \" and become invincible, while Imca can target multiple enemy units with her heavy weapon. \n",
      " Troops are divided into five classes : Scouts, <unk>, Engineers, Lancers and Armored Soldier. Troopers can switch classes by changing their assigned weapon. Changing class does not greatly affect the stats gained while in a previous class. With victory in battle, experience points are awarded to the squad, which are distributed into five different attributes shared by the entire squad, a feature differing from early games'method of distributing to different unit types. \n",
      " = = Plot = = \n",
      " The game takes place during the Second Europan War. Gallian Army Squad 422, also known as \" The Nameless \", are a penal military unit composed of criminals, foreign deserters, and military offenders whose real names are erased from the records and thereon officially referred to by numbers. Ordered by the Gallian military to perform the most dangerous missions that the Regular Army and Militia will not do, they are nevertheless up to the task, exemplified by their motto, <unk> <unk>, meaning \" Always Ready. \" The three main characters are No.7 Kurt Irving, an army officer falsely accused of treason who wishes to redeem himself ; Ace No.1 Imca, a female Darcsen heavy weapons specialist who seeks revenge against the Valkyria who destroyed her home ; and No.13 Riela <unk>, a seemingly jinxed <|end\n",
      "-1\n",
      "\n",
      "\n",
      "\n",
      " Due to low sales of Valkyria Chronicles II, Valkyria Chronicles III was not localized, but a fan translation compatible with the game's expanded edition was released in 2014. Media.Vision would return to the franchise with the development of Valkyria : Azure Revolution for the PlayStation 4. \n",
      " = = Gameplay = = \n",
      " As with previous <unk> Chronicles games, Valkyria Chronicles III is a tactical role @-@ playing game where players take control of a military unit and take part in missions against enemy forces. Stories are told through comic book @-@ like panels with animated character portraits, with characters speaking partially through voiced speech bubbles and partially through unvoiced text. The player progresses through a series of linear missions, gradually unlocked as maps that can be freely scanned through and replayed as they are unlocked. The route to each story location on the map varies depending on an individual player's approach : when one option is selected, the other is sealed off to the player. Outside missions, the player characters rest in a camp, where units can be customized and character growth occurs. Alongside the main story missions are character @-@ specific sub missions relating to different squad members. After the game's completion, additional episodes are unlocked, some of them having a higher difficulty than those found in the rest of the game. There are also love simulation elements related to the game's two main heroines, although they take a very minor role. \n",
      "\n",
      "-1\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for chunk in chunks:\n",
    "    print(tokenizer.decode(input_ids[0][chunk[0]:chunk[1]]))\n",
    "    print(input_text.find(tokenizer.decode(input_ids[0][chunk[0]:chunk[1]])))\n",
    "    print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def string_about_index(ids_index):\n",
    "    return tokenizer.decode(input_ids[0][ids_index-10:ids_index+10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" otherwise dic<|end_of_corpus|>\\n\\nRespond with the chunk and it's corresponding text from the\""
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string_about_index(980)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
